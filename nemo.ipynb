{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2023-04-04 15:51:32 optimizers:54] Apex was not found. Using the lamb or fused_adam optimizer will error out.\n",
      "[NeMo W 2023-04-04 15:51:33 experimental:27] Module <class 'nemo.collections.common.tokenizers.text_to_speech.tts_tokenizers.IPATokenizer'> is experimental, not ready for production and is not fully supported. Use at your own risk.\n",
      "[NeMo W 2023-04-04 15:51:33 experimental:27] Module <class 'nemo.collections.tts.models.radtts.RadTTSModel'> is experimental, not ready for production and is not fully supported. Use at your own risk.\n",
      "[NeMo W 2023-04-04 15:51:34 nemo_logging:349] /home/user/nemo/.venv/lib/python3.10/site-packages/pydub/utils.py:170: RuntimeWarning: Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\n",
      "      warn(\"Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\", RuntimeWarning)\n",
      "    \n",
      "[NeMo W 2023-04-04 15:51:34 experimental:27] Module <class 'nemo.collections.asr.modules.audio_modules.SpectrogramToMultichannelFeatures'> is experimental, not ready for production and is not fully supported. Use at your own risk.\n",
      "[NeMo W 2023-04-04 15:51:34 experimental:27] Module <class 'nemo.collections.tts.models.vits.VitsModel'> is experimental, not ready for production and is not fully supported. Use at your own risk.\n"
     ]
    }
   ],
   "source": [
    "import soundfile as sf\n",
    "from nemo.collections.tts.models.base import SpectrogramGenerator, Vocoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download and load the pretrained tacotron2 model\n",
    "spec_generator = SpectrogramGenerator.from_pretrained(\"tts_en_tacotron2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SpectrogramGenerator.list_available_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download and load the pretrained waveglow model\n",
    "vocoder = Vocoder.from_pretrained(\"tts_hifigan\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All spectrogram generators start by parsing raw strings to a tokenized version of the string\n",
    "parsed = spec_generator.parse(\"You can type your sentence here to get nemo to produce speech.\")\n",
    "# They then take the tokenized string and produce a spectrogram\n",
    "spectrogram = spec_generator.generate_spectrogram(tokens=parsed,)\n",
    "# Finally, a vocoder converts the spectrogram to audio\n",
    "audio = vocoder.convert_spectrogram_to_audio(spec=spectrogram)\n",
    "\n",
    "# Save the audio to disk in a file called speech.wav\n",
    "# Note vocoder return a batch of audio. In this example, we just take the first and only sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sf.write(\"speech_tts_waveglow_268m.wav\", audio.to('cpu').detach().numpy()[0], 22050)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import IPython.display as ipd\n",
    "from matplotlib.pyplot import imshow\n",
    "from matplotlib import pyplot as plt\n",
    "from nemo.collections.tts.models.base import SpectrogramGenerator, Vocoder\n",
    "\n",
    "# List pretrained models available in NeMo\n",
    "print(\"Spectrogram Models\")\n",
    "print(SpectrogramGenerator.list_available_models())\n",
    "\n",
    "print()\n",
    "print(\"Vocoders\")\n",
    "print(Vocoder.list_available_models())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "  device = \"cuda\"\n",
    "else:\n",
    "  device = \"cpu\"\n",
    "\n",
    "# Load our spectrogram and vocoder models onto our CPU\n",
    "spectrogram_model = SpectrogramGenerator.from_pretrained(\"tts_en_tacotron2\").eval().to(device)\n",
    "vocoder = Vocoder.from_pretrained(\"tts_hifigan\").eval().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"You can type your sentence here to get nemo to produce speech.\"\n",
    "\n",
    "# Normalize the text and convert it into individual phonemes/tokens.\n",
    "tokens = spectrogram_model.parse(text, normalize=True)\n",
    "\n",
    "# Generate spectrogram from text\n",
    "spectrogram = spectrogram_model.generate_spectrogram(tokens=tokens)\n",
    "\n",
    "# Invert the spectrogram into audio samples\n",
    "audio = vocoder.convert_spectrogram_to_audio(spec=spectrogram)\n",
    "\n",
    "# Convert output from pytorch tensor to numpy array\n",
    "spectrogram = spectrogram.cpu().detach().numpy()[0]\n",
    "audio = audio.cpu().detach().numpy()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(audio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'\"{text}\"\\n')\n",
    "\n",
    "ipd.Audio(audio, rate=22050)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the spectrogram\n",
    "imshow(spectrogram, origin=\"lower\")\n",
    "plt.xlabel(\"Audio Frame\")\n",
    "plt.ylabel(\"Frequency Band\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
